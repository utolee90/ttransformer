{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "980f5d34-9a2b-4115-ab22-8cfe03781dab",
   "metadata": {},
   "source": [
    "## Linear Regression reduction time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8134b14b-d08e-4d6f-b11f-dff29c7ea715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import time\n",
    "\n",
    "# checkpoint -> result 불러오기\n",
    "import argparse\n",
    "from exp.exp_long_term_forecasting import Exp_Long_Term_Forecast\n",
    "from exp.exp_imputation import Exp_Imputation\n",
    "from exp.exp_short_term_forecasting import Exp_Short_Term_Forecast\n",
    "from exp.exp_long_term_forecasting_partial import Exp_Long_Term_Forecast_Partial\n",
    "from exp.exp_anomaly_detection import Exp_Anomaly_Detection\n",
    "from exp.exp_classification import Exp_Classification\n",
    "from utils.print_args import print_args\n",
    "import random\n",
    "from utils.metrics import *\n",
    "from utils.tools import EarlyStopping\n",
    "\n",
    "from utils.metrics import *\n",
    "from utils.tools import linear_regression_direct, linear_predict\n",
    "from data_provider.data_factory import data_provider\n",
    "from data_provider.data_loader import Dataset_Custom\n",
    "\n",
    "# 모델 훈련셋 결과 확인하기\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 파서 불러오기\n",
    "from commons.parser_write import *\n",
    "\n",
    "# fix random seed\n",
    "fix_seed = 2021\n",
    "random.seed(fix_seed)\n",
    "torch.manual_seed(fix_seed)\n",
    "np.random.seed(fix_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6b00eea-cb8d-477d-ba76-be7b40af39e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scripts_new = \"\"\"--task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./dataset/weather/ \\\n",
    "  --data_path weather.csv \\\n",
    "  --model_id weather_96_96 \\\n",
    "  --model iTransformer \\\n",
    "  --data custom \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 96 \\\n",
    "  --e_layers 3 \\\n",
    "  --d_layers 1 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 21 \\\n",
    "  --dec_in 21 \\\n",
    "  --c_out 21 \\\n",
    "  --des 'Exp' \\\n",
    "  --d_model 512\\\n",
    "  --d_ff 512\\\n",
    "  --itr 1 \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eac1ff21-451f-48b7-9ae8-01ec5505f0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_list2 = []\n",
    "arg = parser.parse_args(scripts_new.split())\n",
    "arg.use_gpu = True if torch.cuda.is_available() and arg.use_gpu else False\n",
    "\n",
    "if arg.use_gpu and arg.use_multi_gpu:\n",
    "    arg.devices = arg.devices.replace(' ', '')\n",
    "    device_ids = arg.devices.split(',')\n",
    "    arg.device_ids = [int(id_) for id_ in device_ids]\n",
    "    arg.gpu = arg.device_ids[0]\n",
    "args_list2.append(arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5dfd1f8a-5e0e-4f04-9512-722748290437",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_96_96_new = \"long_term_forecast_weather_96_96_Mod-iTransformer_data-weather.csv_(96to96)_0(1728617672)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "041fa849-5437-4d32-ab0f-6c75c3d29bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "setting_pairs = [\n",
    "    (weather_96_96_new, args_list2[0])\n",
    "]\n",
    "\n",
    "idx = 0 # 순서\n",
    "col_count = 6 # 한 에포크당 수집 데이터 수\n",
    "num_epochs = 5 # 에포크 ㅅ횟수\n",
    "use_gpu = 0 # 사용 GPU 번호 - 오류 잡기 위해 \n",
    "# q1, q2 = \"lin96\", \"lin24\" # 앙상블 모델 텍스트\n",
    "q1, q2 = \"lin96\", \"lin24\" # 앙상블 모델 텍스트\n",
    "a_init , b_init = 5, -5  # 초기값(sigmoid로변환할  것 감안)  \n",
    "lr = 0.1 #gradient descending 속도. 0.001이 너무 커서 조정햇습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cce83761-11d4-420a-9736-747652be0b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setting_path = setting_pairs[idx][0]\n",
    "args = setting_pairs[idx][1]\n",
    "args.gpu = use_gpu\n",
    "\n",
    "# 모델 호출 - Exp_Long_Term_Forecast - exchange_96_96\n",
    "exp_model = Exp_Long_Term_Forecast(args)\n",
    "exp_model._build_model()\n",
    "device = torch.device(f\"cuda:{use_gpu}\")\n",
    "exp_model.model.device = device\n",
    "# device = exp_model.device\n",
    "\n",
    "# 위의 argument와 맞는 모델 호출\n",
    "checkpoint_path = './checkpoints/'\n",
    "model_path = f\"{checkpoint_path}{setting_path}/checkpoint.pth\"\n",
    "model = torch.load(model_path, map_location=\"cuda:0\")  # 0번 GPU로 매핑\n",
    "exp_model.model.load_state_dict(model, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "739e7998-0a60-4131-8766-6dd732c430cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_provider -> Exchange_rate\n",
    "dataset_input = Dataset_Custom(args, args.root_path,\n",
    "                                    flag='train', size=(args.seq_len, args.label_len, args.pred_len),\n",
    "                                    features='M', data_path = args.data_path,\n",
    "                                    target='OT', scale=True, freq='h', timeenc=0,\n",
    "                                    seasonal_patterns=None, train_ratio=args.train_ratio, test_ratio=args.test_ratio)\n",
    "dataset_input_test = Dataset_Custom(args, args.root_path,\n",
    "                                    flag='test', size=(args.seq_len, args.label_len, args.pred_len),\n",
    "                                    features='M', data_path = args.data_path,\n",
    "                                    target='OT', scale=True, freq='h', timeenc=0,\n",
    "                                    seasonal_patterns=None, train_ratio=args.train_ratio, test_ratio=args.test_ratio)\n",
    "\n",
    "exp_model.model.eval()\n",
    "\n",
    "\n",
    "\n",
    "dataset_input_loader = DataLoader(\n",
    "            dataset_input,\n",
    "            batch_size=args.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=args.num_workers,\n",
    "            drop_last=False)\n",
    "dataset_input_test_loader = DataLoader(\n",
    "            dataset_input_test,\n",
    "            batch_size=1, # 모든 데이터셋을 확인해야 해서 batch_size를 강제로 1로 조정.\n",
    "            shuffle=False,\n",
    "            num_workers=args.num_workers,\n",
    "            drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b556caa2-c544-4ad8-9d1b-e25634f2fb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[t] for t in range(-args.seq_len, 0)])  # X는 입력 feature, shape: [seq_len, 1]\n",
    "X_new = np.array([[t] for t in range(args.pred_len)])  # 예측을 위한 새로운 시간 변수\n",
    "X_concat = np.concatenate([X, X_new], axis=0).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7a133c7-3588-4762-a974-d1663f04e0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combination 모델 제작, 2단계/3단계 대응\n",
    "class CombinedModel(nn.Module):\n",
    "    # 모델 정의 - \n",
    "    def __init__(self, res_A, res_B, res_C):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.res_A = res_A  # iTransformer train_result\n",
    "        self.res_B = res_B  # lin_reg_96 train_result\n",
    "        self.res_C = res_C\n",
    "        self.a = nn.Parameter(torch.ones(1, device=device)*a_init, requires_grad=True)\n",
    "        self.b = nn.Parameter(torch.ones(1, device=device)*b_init, requires_grad=True)\n",
    "        if res_C is not None:\n",
    "            self.c = nn.Parameter(torch.ones(1, device=device)*(1-a_init -b_init), requires_grad=True)\n",
    "        else:\n",
    "            self.c = nn.Parameter(torch.ones(1, device=device)*0.0, requires_grad=True)\n",
    "        # self.c = nn.Parameter(torch.ones(1, device=device)*0.0, requires_grad=True)\n",
    "        # self.d = nn.Parameter(torch.zeros(1, device=device), requires_grad=True)\n",
    "        self.a_sigmoid = torch.sigmoid(self.a)\n",
    "        self.b_sigmoid = torch.sigmoid(self.b)\n",
    "    \n",
    "    def set_a(self, val):\n",
    "        # nn.Parameter를 다시 생성하지 않고 값을 설정\n",
    "        with torch.no_grad():\n",
    "            self.a.copy_(torch.tensor([val], device=device))\n",
    "\n",
    "    def set_b(self, val):\n",
    "        # nn.Parameter를 다시 생성하지 않고 값을 설정\n",
    "        with torch.no_grad():\n",
    "            self.b.copy_(torch.tensor([val], device=device))\n",
    "            \n",
    "    def forward(self, x):\n",
    "        output_A = self.res_A(x)\n",
    "        output_B = self.res_B(x)\n",
    "        \n",
    "        # Apply sigmoid to ensure non-negative coefficients in range (0, 1)\n",
    "        a_sigmoid = torch.sigmoid(self.a)\n",
    "        b_sigmoid = torch.sigmoid(self.b)\n",
    "        \n",
    "        # Ensure the sum constraint by defining c as the remainder\n",
    "        c_sigmoid = torch.clamp(1 - a_sigmoid - b_sigmoid, min=0)\n",
    "    \n",
    "        # Compute the combined output with updated a, b, c\n",
    "        combined_output = a_sigmoid * output_A + b_sigmoid * output_B\n",
    "        \n",
    "        self.a_sigmoid = a_sigmoid\n",
    "        self.b_sigmoid = b_sigmoid\n",
    "        \n",
    "    \n",
    "        if self.res_C is not None:\n",
    "            output_C = self.res_C(x)\n",
    "            combined_output += c_sigmoid * output_C\n",
    "            \n",
    "    \n",
    "        return combined_output\n",
    "    \n",
    "    def get_result(self):\n",
    "        a, b = self.a_sigmoid.detach().cpu().numpy()[0], self.b_sigmoid.detach().cpu().numpy()[0]\n",
    "        return a,b\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e6a192d-ac94-4e8a-a861-b8cf66724c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_lin_reg(batch_x, reg_size=96, device='cuda:0'):\n",
    "    B, L, N = batch_x.shape  # L is the sequence length\n",
    "    # Prepare input tensor by selecting the last `reg_size` elements for each sequence\n",
    "    X = batch_x[:, -reg_size:, :].to(device)  # Shape: [B, reg_size, N]\n",
    "    \n",
    "    # Add bias term to X\n",
    "    X_b = torch.cat([torch.ones((B, reg_size, 1), device=device), X], dim=2)  # Shape: [B, reg_size, N+1]\n",
    "    \n",
    "    # Prepare the output tensor\n",
    "    lin_result = torch.zeros((B, L, N), device=device)\n",
    "    \n",
    "    # Batch computation for linear regression coefficients\n",
    "    for idx in range(B):\n",
    "        XTX = X_b[idx].transpose(0, 1) @ X_b[idx]  # Shape: [N+1, N+1]\n",
    "        XTy = X_b[idx].transpose(0, 1) @ batch_x[idx, -reg_size:, :].to(device)  # Shape: [N+1, N]\n",
    "        \n",
    "        # Solve for theta_best in batch\n",
    "        theta_best = torch.linalg.solve(XTX, XTy)  # Shape: [N+1, N]\n",
    "        \n",
    "        # Predict over the entire sequence\n",
    "        X_full = torch.cat([torch.ones((L, 1), device=device), batch_x[idx, :, :].to(device)], dim=1)  # Shape: [L, N+1]\n",
    "        lin_result[idx] = X_full @ theta_best  # Shape: [L, N]\n",
    "    \n",
    "    return lin_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "226023d6-46dd-41ec-8039-d352d9020439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_output_function\n",
    "\n",
    "def res_iTransformer(batch_x): # S \n",
    "    B, L, N = batch_x.shape  # L은 시퀀스 길이(seq_len)\n",
    "    return exp_model.model(batch_x, None, torch.zeros(B, len(X_new), N), None)\n",
    "\n",
    "def res_lin_reg(batch_x, reg_size=96):\n",
    "    B, L, N = batch_x.shape  # L은 시퀀스 길이(seq_len)\n",
    "    # 각 배치와 변수에 대해 선형 회귀 해를 계산\n",
    "    vals = [[linear_regression_direct(X[-reg_size:], batch_x.permute(0,2,1)[idx, var , -reg_size:], device) for var in range(N)] for idx in range(B)]\n",
    "    lin_result = [[linear_predict(X_new, vals[idx][var], device) for var in range(N)] for idx in range(B)]\n",
    "    # 결과를 3D 텐서로 변환\n",
    "    lin_result = torch.stack([torch.stack(lin_result[idx], dim=0) for idx in range(B)], dim=0).to(device).permute(0,2,1)\n",
    "    return lin_result\n",
    "\n",
    "def zero_model(batch_x): # S 길이\n",
    "    B, L, N = batch_x.shape  # L은 시퀀스 길이(seq_len)\n",
    "    return torch.zeros(B, len(X_new), N)\n",
    "\n",
    "# 함수 도출\n",
    "def get_res_lin(reg_size):\n",
    "    def fn(reg_size):\n",
    "        return res_lin_reg(reg_size)\n",
    "    \n",
    "    return fn\n",
    "    \n",
    "def res_lin_reg_24(batch_x):\n",
    "    B, L, N = batch_x.shape  # L은 시퀀스 길이(seq_len)\n",
    "    # 24 조각에 대해서도 계산\n",
    "    vals_24 = [[linear_regression_direct(X[-24:], batch_x.permute(0,2,1)[idx, var , -24:], device) for var in range(N)] for idx in range(B)]\n",
    "    lin_result_24 = [[linear_predict(X_new, vals_24[idx][var], device) for var in range(N)] for idx in range(B)]\n",
    "    # 결과를 3D 텐서로 변환\n",
    "    lin_result_24 = torch.stack([torch.stack(lin_result_24[idx], dim=0) for idx in range(B)], dim=0).to(device).permute(0,2,1)\n",
    "    return lin_result_24\n",
    "\n",
    "\n",
    "def res_lin_reg_48(batch_x):\n",
    "    B, L, N = batch_x.shape  # L은 시퀀스 길이(seq_len)\n",
    "    # 48 조각에 대해서도 계산\n",
    "    vals_48 = [[linear_regression_direct(X[-48:], batch_x.permute(0,2,1)[idx, var , -48:], device) for var in range(N)] for idx in range(B)]\n",
    "    lin_result_48 = [[linear_predict(X_new, vals_48[idx][var], device) for var in range(N)] for idx in range(B)]\n",
    "    # 결과를 3D 텐서로 변환\n",
    "    lin_result_48 = torch.stack([torch.stack(lin_result_48[idx], dim=0) for idx in range(B)], dim=0).to(device).permute(0,2,1)\n",
    "    return lin_result_48\n",
    "\n",
    "def res_lin_reg_12(batch_x):\n",
    "    B, L, N = batch_x.shape  # L은 시퀀스 길이(seq_len)\n",
    "    # 12 조각에 대해서도 계산\n",
    "    vals_12 = [[linear_regression_direct(X[-12:], batch_x.permute(0,2,1)[idx, var , -12:], device) for var in range(N)] for idx in range(B)]\n",
    "    lin_result_12 = [[linear_predict(X_new, vals_12[idx][var], device) for var in range(N)] for idx in range(B)]\n",
    "    # 결과를 3D 텐서로 변환\n",
    "    lin_result_12 = torch.stack([torch.stack(lin_result_12[idx], dim=0) for idx in range(B)], dim=0).to(device).permute(0,2,1)\n",
    "    return lin_result_12\n",
    "\n",
    "QMAP_FN = {\n",
    "  \"none\": None,\n",
    "  \"lin12\" : res_lin_reg_12,\n",
    "  \"lin24\" : res_lin_reg_24,\n",
    "  \"lin48\" : res_lin_reg_48,\n",
    "  \"lin96\" : res_lin_reg,\n",
    "  \"lin\" : res_lin_reg\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c086f20-f6f0-421b-97d0-92f17aaedd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "QMAP_FN = {\n",
    "  \"none\": None,\n",
    "  \"lin12\" : res_lin_reg_12,\n",
    "  \"lin24\" : res_lin_reg_24,\n",
    "  \"lin48\" : res_lin_reg_48,\n",
    "  \"lin96\" : res_lin_reg,\n",
    "  \"lin\" : res_lin_reg\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd396492-398a-4779-a16b-f94bd859ac7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 100 completed\n",
      "step 200 completed\n",
      "step 300 completed\n",
      "step 400 completed\n",
      "step 500 completed\n",
      "step 600 completed\n",
      "step 700 completed\n",
      "step 800 completed\n",
      "step 900 completed\n",
      "step 1000 completed\n",
      "step 1100 completed\n"
     ]
    }
   ],
   "source": [
    "preds_te_tr = [] # 예측값\n",
    "trues_te_tr = [] # 참값\n",
    "preds_te_lin = [] # 96_lin\n",
    "\n",
    "for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(dataset_input_loader):\n",
    "    batch_x = batch_x.float().to(device)\n",
    "    batch_y = batch_y.float().to(device)\n",
    "\n",
    "    B, L, N = batch_x.shape  # L은 시퀀스 길이(seq_len)\n",
    "\n",
    "    batch_x_mark = batch_x_mark.float().to(device)\n",
    "    batch_y_mark = batch_y_mark.float().to(device)\n",
    "\n",
    "    # decoder input\n",
    "    dec_inp = torch.zeros_like(batch_y[:, -args.pred_len:, :]).float()\n",
    "    dec_inp = torch.cat([batch_y[:, :args.label_len, :], dec_inp], dim=1).float().to(device)\n",
    "    # encoder - decoder\n",
    "\n",
    "    # use_amp도 사용하지 않음, \n",
    "    outputs = exp_model.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "    \n",
    "    # 각 배치와 변수에 대해 선형 회귀 해를 계산\n",
    "    lin_result = res_lin_reg(batch_x, 96).to(device)\n",
    "    \n",
    "    outputs = outputs[:, -args.pred_len:, :]\n",
    "    batch_y = batch_y[:, -args.pred_len:, :].to(device)\n",
    "    outputs = outputs.detach().cpu().numpy()\n",
    "    batch_y = batch_y.detach().cpu().numpy()\n",
    "\n",
    "    pred = outputs\n",
    "    true = batch_y\n",
    "\n",
    "    preds_te_tr.append(pred)\n",
    "    trues_te_tr.append(true)\n",
    "    preds_te_lin.append(lin_result)\n",
    "\n",
    "    if (i+1)%100==0:\n",
    "        print(f\"step {i+1} completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "737bf4bf-36d1-42fc-8b36-435a7b924421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_lin_reg2(batch_x, reg_size=96):\n",
    "    B, L, N = batch_x.shape  # L은 시퀀스 길이(seq_len)\n",
    "    # 각 배치와 변수에 대해 선형 회귀 해를 계산\n",
    "    vals = [[linear_regression_direct(X[-reg_size:], batch_x.permute(0,2,1)[idx, var , -reg_size:], device) for var in range(N)] for idx in range(B)]\n",
    "    lin_result = [[linear_predict(X_new, vals[idx][var], device) for var in range(N)] for idx in range(B)]\n",
    "    # 결과를 3D 텐서로 변환\n",
    "    lin_result = torch.stack([torch.stack(lin_result[idx], dim=0) for idx in range(B)], dim=0).to(device).permute(0,2,1)\n",
    "    return lin_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3d7ce7d6-44a3-4613-8dac-7a4f7f5c9695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 100 completed\n",
      "step 200 completed\n",
      "step 300 completed\n",
      "step 400 completed\n",
      "step 500 completed\n",
      "step 600 completed\n",
      "step 700 completed\n",
      "step 800 completed\n",
      "step 900 completed\n",
      "step 1000 completed\n",
      "step 1100 completed\n"
     ]
    }
   ],
   "source": [
    "preds_te_tr2 = [] # 예측값\n",
    "trues_te_tr2 = [] # 참값\n",
    "preds_te_lin2 = [] # 96_lin\n",
    "\n",
    "for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(dataset_input_loader):\n",
    "    batch_x = batch_x.float().to(device)\n",
    "    batch_y = batch_y.float().to(device)\n",
    "\n",
    "    B, L, N = batch_x.shape  # L은 시퀀스 길이(seq_len)\n",
    "\n",
    "    batch_x_mark = batch_x_mark.float().to(device)\n",
    "    batch_y_mark = batch_y_mark.float().to(device)\n",
    "\n",
    "    # decoder input\n",
    "    dec_inp = torch.zeros_like(batch_y[:, -args.pred_len:, :]).float()\n",
    "    dec_inp = torch.cat([batch_y[:, :args.label_len, :], dec_inp], dim=1).float().to(device)\n",
    "    # encoder - decoder\n",
    "\n",
    "    # use_amp도 사용하지 않음, \n",
    "    outputs = exp_model.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "    \n",
    "    # 각 배치와 변수에 대해 선형 회귀 해를 계산\n",
    "    lin_result = res_lin_reg2(batch_x, 96).to(device)\n",
    "    \n",
    "    outputs = outputs[:, -args.pred_len:, :]\n",
    "    batch_y = batch_y[:, -args.pred_len:, :].to(device)\n",
    "    outputs = outputs.detach().cpu().numpy()\n",
    "    batch_y = batch_y.detach().cpu().numpy()\n",
    "\n",
    "    pred = outputs\n",
    "    true = batch_y\n",
    "\n",
    "    preds_te_tr2.append(pred)\n",
    "    trues_te_tr2.append(true)\n",
    "    preds_te_lin2.append(lin_result)\n",
    "\n",
    "    if (i+1)%100==0:\n",
    "        print(f\"step {i+1} completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e18510a-eb47-49cd-a620-03cce03c47b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_te_tr = np.concatenate(preds_te_tr, axis=0)\n",
    "trues_te_tr = np.concatenate(trues_te_tr, axis=0)\n",
    "preds_te_lin = np.transpose(torch.concat(preds_te_lin, axis=0).detach().cpu().numpy(), (0,2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2a16fbf2-d9e6-4bd6-bd09-093bf947da3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_te_tr2 = np.concatenate(preds_te_tr2, axis=0)\n",
    "trues_te_tr2 = np.concatenate(trues_te_tr2, axis=0)\n",
    "preds_te_lin2 = np.transpose(torch.concat(preds_te_lin2, axis=0).detach().cpu().numpy(), (0,2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "734b03e8-7fae-4c33-b97a-ce2a6f5ea7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_len = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "964d1b2e-1e3c-4c6a-a177-ec23c38a33c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT_LEN 1147 230\n",
      "STEP 0 , (0.9926085, 0.007391512393951416) FIX False\n",
      "vali_loss: 0.17986487408679752\n",
      "50th batch done, loss 0.4444684386253357\n",
      "100th batch done, loss 0.31252753734588623\n",
      "150th batch done, loss 0.3307621479034424\n",
      "200th batch done, loss 0.4776759147644043\n",
      "STEP 230 , (0.8839026, 0.11609739065170288) FIX False\n",
      "vali_loss: 0.17683225202690547\n",
      "250th batch done, loss 0.29288575053215027\n",
      "300th batch done, loss 1.2355951070785522\n",
      "350th batch done, loss 0.36371880769729614\n",
      "400th batch done, loss 0.24600687623023987\n",
      "450th batch done, loss 0.40978124737739563\n",
      "STEP 460 , (0.926933, 0.07306700944900513) FIX False\n",
      "vali_loss: 0.17635128493996838\n",
      "500th batch done, loss 0.35373401641845703\n",
      "550th batch done, loss 0.2922360301017761\n",
      "600th batch done, loss 1.1500778198242188\n",
      "650th batch done, loss 0.44488468766212463\n",
      "STEP 690 , (0.9084992, 0.09150081872940063) FIX False\n",
      "vali_loss: 0.1763129110707734\n",
      "700th batch done, loss 0.37750521302223206\n",
      "750th batch done, loss 0.4997476041316986\n",
      "800th batch done, loss 0.3558930456638336\n",
      "850th batch done, loss 0.33270490169525146\n",
      "900th batch done, loss 0.3756379783153534\n",
      "STEP 920 , (0.88161683, 0.11838316917419434) FIX False\n",
      "vali_loss: 0.1769258491488046\n",
      "950th batch done, loss 0.4979274570941925\n",
      "1000th batch done, loss 1.3424021005630493\n",
      "1050th batch done, loss 0.3283120095729828\n",
      "1100th batch done, loss 0.7940354347229004\n",
      "STEP 1146 , (0.88931775, 0.11068224906921387) FIX False\n",
      "vali_loss: 0.17667000589011952\n",
      "==================================================\n",
      "Epoch 1 DONE\n",
      "\n",
      "0.88931775 0.11068224906921387\n",
      "STEP 0 , (0.88795334, 0.11204665899276733) FIX False\n",
      "vali_loss: 0.1767107206293318\n",
      "50th batch done, loss 0.2668393850326538\n",
      "100th batch done, loss 0.3875896632671356\n",
      "150th batch done, loss 0.4652861952781677\n",
      "200th batch done, loss 0.3984729051589966\n",
      "STEP 230 , (0.89527464, 0.10472536087036133) FIX False\n",
      "vali_loss: 0.17651651124603696\n",
      "250th batch done, loss 0.3063235878944397\n",
      "300th batch done, loss 0.3561756908893585\n",
      "350th batch done, loss 0.34774744510650635\n",
      "400th batch done, loss 0.4317329525947571\n",
      "450th batch done, loss 0.3420996069908142\n",
      "STEP 460 , (0.8936031, 0.10639691352844238) FIX False\n",
      "vali_loss: 0.1765559337921198\n",
      "500th batch done, loss 0.31436046957969666\n",
      "550th batch done, loss 0.3294072449207306\n",
      "600th batch done, loss 0.3957287669181824\n",
      "650th batch done, loss 0.4572579562664032\n",
      "STEP 690 , (0.87227666, 0.1277233362197876) FIX False\n",
      "vali_loss: 0.17732607112674537\n",
      "700th batch done, loss 0.23970647156238556\n",
      "750th batch done, loss 0.290528267621994\n",
      "800th batch done, loss 0.3372358977794647\n",
      "850th batch done, loss 0.45608898997306824\n",
      "900th batch done, loss 0.32253944873809814\n",
      "STEP 920 , (0.91670984, 0.08329015970230103) FIX False\n",
      "vali_loss: 0.1762852907702983\n",
      "950th batch done, loss 1.2717082500457764\n",
      "1000th batch done, loss 0.3412714898586273\n",
      "1050th batch done, loss 0.28202494978904724\n",
      "1100th batch done, loss 0.30529287457466125\n",
      "STEP 1146 , (0.9189669, 0.08103311061859131) FIX False\n",
      "vali_loss: 0.17629027907026426\n",
      "==================================================\n",
      "Epoch 2 DONE\n",
      "\n",
      "0.9189669 0.08103311061859131\n",
      "STEP 0 , (0.918658, 0.08134198188781738) FIX False\n",
      "vali_loss: 0.1762892716934841\n",
      "50th batch done, loss 0.27336886525154114\n",
      "100th batch done, loss 1.220090389251709\n",
      "150th batch done, loss 0.3679852783679962\n",
      "200th batch done, loss 0.35197576880455017\n",
      "STEP 230 , (0.899962, 0.10003799200057983) FIX False\n",
      "vali_loss: 0.17642335095401812\n",
      "250th batch done, loss 0.6854020953178406\n",
      "300th batch done, loss 0.37489810585975647\n",
      "350th batch done, loss 0.38052695989608765\n",
      "400th batch done, loss 0.3391090929508209\n",
      "450th batch done, loss 0.4016396701335907\n",
      "STEP 460 , (0.8976399, 0.10236012935638428) FIX False\n",
      "vali_loss: 0.17646682661701577\n",
      "500th batch done, loss 0.32006868720054626\n",
      "550th batch done, loss 0.4372662603855133\n",
      "600th batch done, loss 0.2752948999404907\n",
      "650th batch done, loss 0.4277874529361725\n",
      "STEP 690 , (0.9172147, 0.08278530836105347) FIX False\n",
      "vali_loss: 0.1762860307636896\n",
      "700th batch done, loss 0.26518189907073975\n",
      "750th batch done, loss 0.42888933420181274\n",
      "800th batch done, loss 0.30838340520858765\n",
      "850th batch done, loss 0.34888961911201477\n",
      "900th batch done, loss 1.2772881984710693\n",
      "STEP 920 , (0.90615827, 0.09384173154830933) FIX False\n",
      "vali_loss: 0.17633650620952704\n",
      "950th batch done, loss 0.2874685823917389\n",
      "1000th batch done, loss 0.37571650743484497\n",
      "1050th batch done, loss 0.37571287155151367\n",
      "1100th batch done, loss 0.3150379955768585\n",
      "STEP 1146 , (0.8892644, 0.11073559522628784) FIX False\n",
      "vali_loss: 0.17667275124965345\n",
      "==================================================\n",
      "Epoch 3 DONE\n",
      "\n",
      "0.8892644 0.11073559522628784\n",
      "STEP 0 , (0.8806159, 0.11938410997390747) FIX False\n",
      "vali_loss: 0.17696610124701828\n",
      "50th batch done, loss 0.3809477388858795\n",
      "100th batch done, loss 0.3148214817047119\n",
      "150th batch done, loss 0.3213622570037842\n",
      "200th batch done, loss 0.3517506718635559\n",
      "STEP 230 , (0.89878863, 0.10121136903762817) FIX False\n",
      "vali_loss: 0.17644469826316375\n",
      "250th batch done, loss 0.4443463683128357\n",
      "300th batch done, loss 0.6840235590934753\n",
      "350th batch done, loss 0.26033300161361694\n",
      "400th batch done, loss 1.387555718421936\n",
      "450th batch done, loss 0.5228754281997681\n",
      "STEP 460 , (0.9099806, 0.09001940488815308) FIX False\n",
      "vali_loss: 0.1763039272453683\n",
      "500th batch done, loss 0.2277652621269226\n",
      "550th batch done, loss 0.3611845076084137\n",
      "600th batch done, loss 0.3778453767299652\n",
      "650th batch done, loss 0.32599711418151855\n",
      "STEP 690 , (0.8933772, 0.10662281513214111) FIX False\n",
      "vali_loss: 0.17656211003986458\n",
      "700th batch done, loss 0.36264681816101074\n",
      "750th batch done, loss 0.4183427691459656\n",
      "800th batch done, loss 0.4089377820491791\n",
      "850th batch done, loss 0.3308597505092621\n",
      "900th batch done, loss 0.36985692381858826\n",
      "STEP 920 , (0.9078412, 0.09215879440307617) FIX False\n",
      "vali_loss: 0.17632023081303283\n",
      "950th batch done, loss 0.29394200444221497\n",
      "1000th batch done, loss 0.38533756136894226\n",
      "1050th batch done, loss 0.8126004934310913\n",
      "1100th batch done, loss 0.28727656602859497\n",
      "STEP 1146 , (0.9012785, 0.09872150421142578) FIX False\n",
      "vali_loss: 0.17640153710630144\n",
      "==================================================\n",
      "Epoch 4 DONE\n",
      "\n",
      "0.9012785 0.09872150421142578\n",
      "STEP 0 , (0.90080065, 0.09919935464859009) FIX False\n",
      "vali_loss: 0.176409302819028\n",
      "50th batch done, loss 0.2951469123363495\n",
      "100th batch done, loss 0.2555008828639984\n",
      "150th batch done, loss 0.34335318207740784\n",
      "200th batch done, loss 0.26789405941963196\n",
      "STEP 230 , (0.8756073, 0.12439268827438354) FIX False\n",
      "vali_loss: 0.17717365573732127\n",
      "250th batch done, loss 0.34779462218284607\n",
      "300th batch done, loss 0.5935783982276917\n",
      "350th batch done, loss 0.2475021779537201\n",
      "400th batch done, loss 0.3477380573749542\n",
      "450th batch done, loss 0.3415047228336334\n",
      "STEP 460 , (0.9121801, 0.08781987428665161) FIX False\n",
      "vali_loss: 0.17629245604694815\n",
      "500th batch done, loss 0.45559507608413696\n",
      "550th batch done, loss 0.28818097710609436\n",
      "600th batch done, loss 0.3001396059989929\n",
      "650th batch done, loss 0.5273861885070801\n",
      "STEP 690 , (0.91810614, 0.08189386129379272) FIX False\n",
      "vali_loss: 0.17628787831114037\n",
      "700th batch done, loss 0.30103135108947754\n",
      "750th batch done, loss 0.6273849606513977\n",
      "800th batch done, loss 0.4099123775959015\n",
      "850th batch done, loss 0.4476194977760315\n",
      "900th batch done, loss 0.3502421975135803\n",
      "STEP 920 , (0.91455424, 0.08544576168060303) FIX False\n",
      "vali_loss: 0.17628600131074693\n",
      "950th batch done, loss 0.3121952712535858\n",
      "1000th batch done, loss 0.32618963718414307\n",
      "1050th batch done, loss 0.3279874920845032\n",
      "1100th batch done, loss 0.2537425756454468\n",
      "STEP 1146 , (0.815213, 0.18478697538375854) FIX False\n",
      "vali_loss: 0.181842579695206\n",
      "==================================================\n",
      "Epoch 5 DONE\n",
      "\n",
      "0.815213 0.18478697538375854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CombinedModel()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 실험\n",
    "combine_model_test = CombinedModel(res_iTransformer, res_lin_reg, None )\n",
    "# combine_model_test.set_a(0.95)\n",
    "# combine_model_test.set_b(0.025)\n",
    "# combine_model_test training\n",
    "combine_model_test.train()\n",
    "# torch.nn.utils.clip_grad_norm_(combine_model_test.parameters(), max_norm=0.8) # gradient clipping - 크기 제한\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "# optimizer = torch.optim.Adam(combine_model_test.parameters(), lr=lr, weight_decay=1e-4)\n",
    "optimizer = torch.optim.Adam([combine_model_test.a, combine_model_test.b], lr=lr)\n",
    "\n",
    "# 검증 데이터셋 결과 확인\n",
    "def vali(vali_data, vali_loader, criterion):\n",
    "    total_loss = []\n",
    "    combine_model_test.eval()\n",
    "    len_data = (len(vali_data)-1)//5 \n",
    "    with torch.no_grad():\n",
    "        for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(vali_loader):\n",
    "            batch_x = batch_x.float().to(device)\n",
    "            batch_y = batch_y.float().to(device)\n",
    "            targets = batch_y[:, -args.pred_len:, :].to(device)\n",
    "            outputs = combine_model_test(batch_x)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss.append(loss)\n",
    "            \n",
    "        \n",
    "    total_loss = [v.item() for v in total_loss]\n",
    "    total_loss = np.average(total_loss)\n",
    "    combine_model_test.train()\n",
    "    return total_loss\n",
    "\n",
    "# 모델 훈련\n",
    "\n",
    "loss_points = [] # (a, b)\n",
    "# input_len = int(np.ceil(len(dataset_input) / args.batch_size) )\n",
    "input_len_div = int(np.ceil(input_len / (col_count - 1)))\n",
    "\n",
    "print(\"INPUT_LEN\", input_len, input_len_div)\n",
    "early_stopping = EarlyStopping(patience=2, verbose=True)\n",
    "for epoch in range(num_epochs):\n",
    "    cnt = 0\n",
    "    train_loss = []\n",
    "    # exp_model.train()\n",
    "\n",
    "    \n",
    "    path = os.path.join(args.checkpoints, setting_path)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(dataset_input_loader):\n",
    "        cnt += 1\n",
    "        batch_x = batch_x.float().to(device)\n",
    "        batch_y = batch_y.float().to(device)\n",
    "        targets = batch_y[:, -args.pred_len:, :].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = combine_model_test(batch_x)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss)\n",
    "        if (cnt+1) % 50 == 0:\n",
    "            print(f\"{cnt+1}th batch done, loss {loss}\")\n",
    "        if i == input_len -1 or i % input_len_div == 0:\n",
    "            a, b = torch.sigmoid(combine_model_test.a).detach().cpu().numpy()[0], 1 - torch.sigmoid(combine_model_test.a).detach().cpu().numpy()[0]\n",
    "            print(f\"STEP {i} , {a,b}\", \"FIX\", (a,b) ==combine_model_test.get_result() )\n",
    "            loss_points.append((a,b))\n",
    "            vali_loss = vali(dataset_input_test, dataset_input_test_loader, criterion)\n",
    "            print(\"vali_loss:\", vali_loss)\n",
    "\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Epoch {epoch+1} DONE\")\n",
    "    print()\n",
    "    train_loss = [v.item() for v in train_loss]\n",
    "    train_loss = np.average(train_loss)\n",
    "    vali_loss = vali(dataset_input_test, dataset_input_test_loader, criterion)\n",
    "    # print(\"vali_loss:\", vali_loss)\n",
    "    # print()\n",
    "    print(a,b)\n",
    "    # early_stopping(vali_loss, combine_model_test, path)\n",
    "    # if early_stopping.early_stop:\n",
    "    #    print(\"Early stopping\")\n",
    "    #    break\n",
    "    model_path = path + '/' + 'checkpoint_ensenble.pth'\n",
    "    # torch.save(combine_model_test.state_dict(), model_path)\n",
    "    # combine_model_test.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "# 훈련 결과 도출\n",
    "combine_model_test.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1cd40968-690d-446e-b956-71a3a94f6fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선형회귀 계수 결과값으로 계산\n",
    "def get_np_pred_lin(np_pred, reg_size=96):\n",
    "    # 이제 계산도 한다\n",
    "    # 각 배치와 변수에 대해 선형 회귀 해를 계산\n",
    "    B, L, N = np_pred.shape  # L은 시퀀스 길이(seq_len)\n",
    "    vals = [[linear_regression_direct(X[-reg_size:], dataset_input_test[idx][0][-reg_size:, var]) for var in range(N)] for idx in range(B)]\n",
    "    lin_result = [[linear_predict(X_new, vals[idx][var]) for var in range(N)] for idx in range(B)]\n",
    "    # 결과를 numpy 모듈로 변경\n",
    "    np_pred_lin = torch.stack([torch.stack(lin_result[idx], dim=0) for idx in range(B)], dim=0).to(device).permute(0,2,1).detach().cpu().numpy()\n",
    "    return np_pred_lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0a4002d-f071-45c0-8fb0-393415f1c064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제 데이터 셋 호출\n",
    "result_list = ['pred.npy', 'true.npy']\n",
    "result_path = './results/'\n",
    "np_pred = np.load(f\"{result_path}{setting_path}/{result_list[0]}\")\n",
    "np_true = np.load(f\"{result_path}{setting_path}/{result_list[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ead9f10b-ca84-4b52-96b3-f710025034da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10444, 96, 21)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "62e1bc35-e1e5-40db-854a-7c2f09413d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_np_pred_lin(np_pred, dataset_input_test, reg_size=96, device='cuda:0'):\n",
    "    B, L, N = np_pred.shape  # B: Batch size, L: Sequence length, N: Number of variables\n",
    "\n",
    "    # Prepare input tensor for the regression by selecting the last `reg_size` elements\n",
    "    X  = torch.Tensor(np_pred[:, -reg_size:, :]).to(device)\n",
    "    # X = np_pred[:, -reg_size:, :]  # Shape: [B, reg_size, N]\n",
    "    \n",
    "    # Add bias term to X\n",
    "    X_b = torch.cat([torch.ones((B, reg_size, 1), device=device), X], dim=2)  # Shape: [B, reg_size, N+1]\n",
    "\n",
    "    # Initialize tensor for storing linear regression coefficients and predictions\n",
    "    lin_result = torch.zeros((B, L, N), device=device)\n",
    "\n",
    "    for idx in range(B):\n",
    "        # Select data from `dataset_input_test` for the regression target (for each variable)\n",
    "        target = torch.Tensor(dataset_input_test[idx][0][-reg_size:, :]).to(device)  # Shape: [reg_size, N]\n",
    "\n",
    "        # Compute batch matrix products X^T X and X^T y\n",
    "        XTX = X_b[idx].transpose(0, 1) @ X_b[idx]  # Shape: [N+1, N+1]\n",
    "        XTy = X_b[idx].transpose(0, 1) @ target  # Shape: [N+1, N]\n",
    "\n",
    "        # Solve for linear regression coefficients (theta_best)\n",
    "        theta_best = torch.linalg.solve(XTX, XTy)  # Shape: [N+1, N]\n",
    "\n",
    "        # Use the learned coefficients to make predictions for the full sequence\n",
    "        X_full = torch.cat([torch.ones((L, 1), device=device), torch.Tensor(np_pred[idx, :, :]).to(device)], dim=1)  # Shape: [L, N+1]\n",
    "        lin_result[idx] = X_full @ theta_best  # Shape: [L, N]\n",
    "\n",
    "    # Convert the final result back to NumPy\n",
    "    # np_pred_lin = lin_result.permute(0, 2, 1).detach().cpu().numpy()  # Shape: [B, N, L]\n",
    "    np_pred_lin = lin_result.detach().cpu().numpy()\n",
    "    \n",
    "    return np_pred_lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bee272dc-90db-46a1-bbec-95146cc36799",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np_pred_first = get_np_pred_lin(np_pred, 96)\n",
    "np_pred_second = np.zeros(np_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "19f3967e-622e-4cd1-8674-8fa4a1f33993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10444, 96, 21), (10444, 96, 21))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_pred.shape, np_pred_first.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f287628b-3c04-48c1-8c83-54fd1550db8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMBI 30\n"
     ]
    }
   ],
   "source": [
    "print(\"COMBI\", len(loss_points))\n",
    "\n",
    "loss_points_map = [] # a,b,c, mae, mse, smae, std_ratio, slope_ratio\n",
    "\n",
    "# loss_points에서 수집한 도트들을 비교 -> 최소 MSE, 최소 MAE 검색, 최소 SMAE 검색\n",
    "for j, (a,b) in enumerate(loss_points):\n",
    "    res_temp = a*np_pred + b*np_pred_first + (1-a-b)*np_pred_second\n",
    "    mse_step = MSE(res_temp, np_true)\n",
    "    mae_step = MAE(res_temp, np_true)\n",
    "    smae_step = SMAE(res_temp, np_true)\n",
    "    # std_step = STD_RATIO(res_temp, np_true)\n",
    "    # slope_step = SLOPE_RATIO(res_temp, np_true)\n",
    "    \n",
    "    loss_points_map.append({\"cnt\": j, \"a\":a,\"b\":b,\"MSE\":mse_step,\"MAE\": mae_step,\"SMAE\": smae_step})\n",
    "    # loss_points_map.append({\"cnt\": j, \"a\":a,\"b\":b,\"MSE\":mse_step,\"MAE\": mae_step,\"SMAE\": smae_step, \"STD_RATIO\": std_step, \"slope_step\": slope_step})\n",
    "\n",
    "# MSE 기준으로 정렬\n",
    "main_key = \"MSE\" \n",
    "new_loss_points_map = sorted(loss_points_map, key=lambda x: x[main_key])\n",
    "        \n",
    "# 우선 mae 기준으로 할당.\n",
    "a, b = new_loss_points_map[0][\"a\"], new_loss_points_map[0][\"b\"]\n",
    "\n",
    "# 마지막으로 비교\n",
    "final_res = a*np_pred + b* np_pred_first + (1-a-b)*np_pred_second\n",
    "# final_res = a*np_pred + (1-a)*np_pred_lin\n",
    "\n",
    "# 메트릭 비교하기 (원본 iTransformer)\n",
    "with open(f'run_ensenble_txt_{setting_path}_{q1}_{q2}.txt', 'w', encoding='utf8') as A:\n",
    "    wr = \"TRAIN_PRED\\n\"\n",
    "    wr += f\"{MSE(np_pred, np_true), MAE(np_pred, np_true), SMAE(np_pred, np_true), STD_RATIO(np_pred, np_true), SLOPE_RATIO(np_pred, np_true)} \\n\"\n",
    "    wr += \"TRAIN_ENSEMBLE_PRED\\n\"\n",
    "    wr += f\"{MSE(final_res, np_true), MAE(final_res, np_true), SMAE(final_res, np_true), STD_RATIO(final_res, np_true), SLOPE_RATIO(final_res, np_true)}\\n\"\n",
    "    wr += \"LIN_PRED\\n\"\n",
    "    wr += \"TRAIN_PRED_FIRST\\n\"\n",
    "    wr += f\"{MSE(np_pred_first, np_true), MAE(np_pred_first, np_true), SMAE(np_pred_first, np_true), STD_RATIO(np_pred_first, np_true), SLOPE_RATIO(np_pred_first, np_true)}\\n\"\n",
    "    wr += \"TRAIN_PRED_SECOND\\n\"\n",
    "    wr += f\"{MSE(np_pred_second, np_true), MAE(np_pred_second, np_true), SMAE(np_pred_second, np_true), STD_RATIO(np_pred_second, np_true), SLOPE_RATIO(np_pred_second, np_true)}\\n\"\n",
    "    wr += f\"loss_combi : {loss_points}\\n\"\n",
    "    A.write(wr)\n",
    "\n",
    "# 메트릭 저장\n",
    "metric_path = f\"./results/{setting_path}/\"\n",
    "metric_ensemble = [MSE(np_pred, np_true), MAE(np_pred, np_true), SMAE(np_pred, np_true), REC_CORR(np_pred, np_true), STD_RATIO(np_pred, np_true), SLOPE_RATIO(np_pred, np_true)]\n",
    "np.save(metric_path + \"metrics_ensemble.npy\", metric_ensemble)\n",
    "np.save(metric_path + \"pred_ensemble.npy\", final_res)\n",
    "np.save(metric_path + \"coef_col.npy\", loss_points)\n",
    "np.save(metric_path + \"coef_metric.npy\", loss_points_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fc4c6423-659a-4805-b6bd-0cbd55fff45b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'cnt': 0,\n",
       "  'a': 0.9926085,\n",
       "  'b': 0.007391512393951416,\n",
       "  'MSE': 0.17493676662685725,\n",
       "  'MAE': 0.21573891760815053,\n",
       "  'SMAE': 0.024052868946994002},\n",
       " {'cnt': 1,\n",
       "  'a': 0.8839026,\n",
       "  'b': 0.11609739065170288,\n",
       "  'MSE': 0.17272305603149193,\n",
       "  'MAE': 0.21731697488324556,\n",
       "  'SMAE': 0.021546886682394503},\n",
       " {'cnt': 2,\n",
       "  'a': 0.926933,\n",
       "  'b': 0.07306700944900513,\n",
       "  'MSE': 0.17220167736684663,\n",
       "  'MAE': 0.21524877447282556,\n",
       "  'SMAE': 0.022538860348570274},\n",
       " {'cnt': 3,\n",
       "  'a': 0.9084992,\n",
       "  'b': 0.09150081872940063,\n",
       "  'MSE': 0.17220079146008135,\n",
       "  'MAE': 0.2159326311270188,\n",
       "  'SMAE': 0.02211390819012683},\n",
       " {'cnt': 4,\n",
       "  'a': 0.88161683,\n",
       "  'b': 0.11838316917419434,\n",
       "  'MSE': 0.17280198001567293,\n",
       "  'MAE': 0.2174721499927771,\n",
       "  'SMAE': 0.021494192957934574},\n",
       " {'cnt': 5,\n",
       "  'a': 0.88931775,\n",
       "  'b': 0.11068224906921387,\n",
       "  'MSE': 0.17255670464275422,\n",
       "  'MAE': 0.216967118285253,\n",
       "  'SMAE': 0.02167172120371889},\n",
       " {'cnt': 6,\n",
       "  'a': 0.88795334,\n",
       "  'b': 0.11204665899276733,\n",
       "  'MSE': 0.17259588548450094,\n",
       "  'MAE': 0.21705291266737034,\n",
       "  'SMAE': 0.021640267657998934},\n",
       " {'cnt': 7,\n",
       "  'a': 0.89527464,\n",
       "  'b': 0.10472536087036133,\n",
       "  'MSE': 0.172407213708014,\n",
       "  'MAE': 0.21661151914344196,\n",
       "  'SMAE': 0.02180904459113518},\n",
       " {'cnt': 8,\n",
       "  'a': 0.8936031,\n",
       "  'b': 0.10639691352844238,\n",
       "  'MSE': 0.1724456194761879,\n",
       "  'MAE': 0.21670818681437665,\n",
       "  'SMAE': 0.021770510536781234},\n",
       " {'cnt': 9,\n",
       "  'a': 0.87227666,\n",
       "  'b': 0.1277233362197876,\n",
       "  'MSE': 0.1731781836950255,\n",
       "  'MAE': 0.2181520532677187,\n",
       "  'SMAE': 0.021278875323237516},\n",
       " {'cnt': 10,\n",
       "  'a': 0.91670984,\n",
       "  'b': 0.08329015970230103,\n",
       "  'MSE': 0.17215967293498247,\n",
       "  'MAE': 0.2155892793059793,\n",
       "  'SMAE': 0.02230318744110643},\n",
       " {'cnt': 11,\n",
       "  'a': 0.9189669,\n",
       "  'b': 0.08103311061859131,\n",
       "  'MSE': 0.17216005439956752,\n",
       "  'MAE': 0.2155056444003578,\n",
       "  'SMAE': 0.02235521889290108},\n",
       " {'cnt': 12,\n",
       "  'a': 0.918658,\n",
       "  'b': 0.08134198188781738,\n",
       "  'MSE': 0.17215970458937574,\n",
       "  'MAE': 0.21551680980519528,\n",
       "  'SMAE': 0.022348098515635125},\n",
       " {'cnt': 13,\n",
       "  'a': 0.899962,\n",
       "  'b': 0.10003799200057983,\n",
       "  'MSE': 0.17231425752631824,\n",
       "  'MAE': 0.21635334865189856,\n",
       "  'SMAE': 0.02191710187141299},\n",
       " {'cnt': 14,\n",
       "  'a': 0.8976399,\n",
       "  'b': 0.10236012935638428,\n",
       "  'MSE': 0.1723575919717135,\n",
       "  'MAE': 0.2164788703404704,\n",
       "  'SMAE': 0.02186356995089919},\n",
       " {'cnt': 15,\n",
       "  'a': 0.9172147,\n",
       "  'b': 0.08278530836105347,\n",
       "  'MSE': 0.1721593207542362,\n",
       "  'MAE': 0.21557016147816838,\n",
       "  'SMAE': 0.022314825686070384},\n",
       " {'cnt': 16,\n",
       "  'a': 0.90615827,\n",
       "  'b': 0.09384173154830933,\n",
       "  'MSE': 0.17222473050322964,\n",
       "  'MAE': 0.21604154828455144,\n",
       "  'SMAE': 0.022059943457542985},\n",
       " {'cnt': 17,\n",
       "  'a': 0.8892644,\n",
       "  'b': 0.11073559522628784,\n",
       "  'MSE': 0.17255820196096555,\n",
       "  'MAE': 0.21697044229520937,\n",
       "  'SMAE': 0.021670491479174093},\n",
       " {'cnt': 18,\n",
       "  'a': 0.8806159,\n",
       "  'b': 0.11938410997390747,\n",
       "  'MSE': 0.17283816779580513,\n",
       "  'MAE': 0.21754149441895274,\n",
       "  'SMAE': 0.02147111840569615},\n",
       " {'cnt': 19,\n",
       "  'a': 0.89878863,\n",
       "  'b': 0.10121136903762817,\n",
       "  'MSE': 0.1723354878058047,\n",
       "  'MAE': 0.21641619761026912,\n",
       "  'SMAE': 0.021890052183632956},\n",
       " {'cnt': 20,\n",
       "  'a': 0.9099806,\n",
       "  'b': 0.09001940488815308,\n",
       "  'MSE': 0.1721884424176493,\n",
       "  'MAE': 0.21586620778009893,\n",
       "  'SMAE': 0.02214805905764381},\n",
       " {'cnt': 21,\n",
       "  'a': 0.8933772,\n",
       "  'b': 0.10662281513214111,\n",
       "  'MSE': 0.1724510218030408,\n",
       "  'MAE': 0.2167214370082603,\n",
       "  'SMAE': 0.021765302820822296},\n",
       " {'cnt': 22,\n",
       "  'a': 0.9078412,\n",
       "  'b': 0.09215879440307617,\n",
       "  'MSE': 0.17220697252073416,\n",
       "  'MAE': 0.21596275184680117,\n",
       "  'SMAE': 0.02209873998864653},\n",
       " {'cnt': 23,\n",
       "  'a': 0.9012785,\n",
       "  'b': 0.09872150421142578,\n",
       "  'MSE': 0.17229205902255326,\n",
       "  'MAE': 0.21628427424523292,\n",
       "  'SMAE': 0.02194745070407353},\n",
       " {'cnt': 24,\n",
       "  'a': 0.90080065,\n",
       "  'b': 0.09919935464859009,\n",
       "  'MSE': 0.1722999182943602,\n",
       "  'MAE': 0.2163091686310529,\n",
       "  'SMAE': 0.02193643487466708},\n",
       " {'cnt': 25,\n",
       "  'a': 0.8756073,\n",
       "  'b': 0.12439268827438354,\n",
       "  'MSE': 0.17303413271504808,\n",
       "  'MAE': 0.21790117683713078,\n",
       "  'SMAE': 0.021355656305627194},\n",
       " {'cnt': 26,\n",
       "  'a': 0.9121801,\n",
       "  'b': 0.08781987428665161,\n",
       "  'MSE': 0.17217411132998792,\n",
       "  'MAE': 0.2157712013030237,\n",
       "  'SMAE': 0.022198764534134736},\n",
       " {'cnt': 27,\n",
       "  'a': 0.91810614,\n",
       "  'b': 0.08189386129379272,\n",
       "  'MSE': 0.17215931452553482,\n",
       "  'MAE': 0.21553697993164775,\n",
       "  'SMAE': 0.022335376093521087},\n",
       " {'cnt': 28,\n",
       "  'a': 0.91455424,\n",
       "  'b': 0.08544576168060303,\n",
       "  'MSE': 0.1721640128817517,\n",
       "  'MAE': 0.2156735411505917,\n",
       "  'SMAE': 0.022253494639475492},\n",
       " {'cnt': 29,\n",
       "  'a': 0.815213,\n",
       "  'b': 0.18478697538375854,\n",
       "  'MSE': 0.1773506193526791,\n",
       "  'MAE': 0.22382653928497484,\n",
       "  'SMAE': 0.01996339483014254}]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_points_map"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
